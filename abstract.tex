{Demand for intelligent agents has been a large motivation in the design and implementation of enemy AI in games. Players want opponents that can act intelligently and pose a challenge. We propose MARLs, a cooperative Multi-Agent Reinforcement Q-learning approach to AI agents with limited message sharing. We believe MARLs will give the enemy agents a human-like feel which occasionally allows players to capitalize on a wrong choice that the AI makes. To evaluate the performance of this cooperative agent, we compare it against an oracle agent with unlimited message sharing and an independent agent with no message passing capacity. We found only minor improvements in performance between the different AI when limiting policy sharing between agents.
}

%{Demand for intelligent agents has been a large motivation in the design and implementation of enemy AI in games. Players want to play against enemies that can act intelligently and are also enjoyable opponents. We propose MARLs, a cooperative Multi-Agent Reinforcement Q-learning approach to AI agents with limited message sharing. We believe MARLs will give the enemy agents a human-like feel which occasionally allows players to capitalize on a ”wrong” choice that the AI makes. To evaluate the performance of this cooperative agent, we compare it against an oracle agent with unlimited message sharing and an individual agent with no message passing capacity. The evaluation shows that the oracle agent performs better than the cooperative agent and the cooperative agent performs better than the individual agent.}

%{Demand for intelligent agents has been a large motivation in the design and implementation of enemy AI in games. Players want to play against   enemies that can act intelligently and also fun to play against. We propose MARLS, a Multi-Agent Reinforcement Q-learning approach to AI agents with limited cooperative sharing. We believe MARLS will give the enemy agents a human like feel which occasionally allows players to capitalize on a "wrong" choice that AI makes. To evaluate the performance of this cooperative agent we compare it against an oracle agent with unlimited message sharing and an individual agent with zero message passing capacity. The evaluation shows that the oracle agent performs better than the cooperative agent and the cooperative agent performs better than the individual agent.}



%Players don't want to play against easy enemies who make consistently poor decisions or follows obvious patterns. Players also don't want enemies so difficult players are forced to find scenarios the AI will act unintelligibly. The intelligent agents AI design strives for are agents which act intelligently, but are fun to play against.








%Expected results should be that oracle
%outperforms the individual and limited sharing coop, because we have treated
%oracle as infinite sharing coop.
%\jake{We could also see how a single unit does
%against multiple units as an additional comparison point. So does a single unit
%against a single enemy perform generally as well as multiple units against
%multiple enemies?} 
%The limited sharing coop should vary in accuracy based on the
%amount of sharing that takes place. 
%\jake{Find the sweet spot of
%accuracy(efficiency) vs. resource passing(complexity)} Individual should be a
%lower bound compared to coop and oracle, since no information is shared between
%units.}